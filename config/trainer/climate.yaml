_target_: trainers.base_trainer.BaseTrainer

epochs: 20
log_every: 1000
optimizer:
    _target_: torch.optim.Adam
    lr: 0.0001
    betas: [0.9, 0.999]
dataloader:
    batch_size: 32
    num_workers: 0
    sampler:
        _target_: data.climate_data_utils.BatchSampler
        weights: [0.1, 0.9]
        num_samples: 1000
ema:
    _target_: ema_pytorch.EMA
    beta: 0.995
    update_every: 10
